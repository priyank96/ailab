{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b2497b3-60ee-7cd0-0625-f103214c0ed4",
    "_uuid": "9d788352e7fe1ede8003a4b86cda0d589d4f395c"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39c44f0e-d62c-7e11-a542-4fcd58e21442",
    "_uuid": "950a84c64d8101c7a9f3d318a5b17290547a255c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6c53202d-5c34-4859-e7e9-8ef5c7068287",
    "_uuid": "58ea616bc76d734aa7556b2d523709b1ab63167e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bc2702e-d6f4-df5f-b80e-50ab23a6d29e",
    "_uuid": "84dffe03ff707b7c18ca3125538f5f5e77c77d6b"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "89c8c923-c0bf-7b35-9ab8-e63f00b74e5a",
    "_uuid": "ace314aaea94e997a463d0990da60a76e0dab37d"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('inputs.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c0ec63b-cdf8-8e29-812b-0fbbfcea2929",
    "_uuid": "8937c5976a4cdb2a6d7ccd2a93c510bff1c00d3c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "43632d2d-6160-12ce-48b0-e5eb1c207076",
    "_uuid": "865e99cc912696ddb5de645c52b619c3db05416b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                      not a good Idea\n",
      "1                                             Horrible\n",
      "2                                       LOVE LOVE LOVE\n",
      "3    don't waste your money, pay more and buy one a...\n",
      "4            leopard home button sticker for iphone 4s\n",
      "Name: text, dtype: object\n",
      "------------------\n",
      "0                                      not a good idea\n",
      "1                                             horrible\n",
      "2                                       love love love\n",
      "3    dont waste your money pay more and buy one at ...\n",
      "4            leopard home button sticker for iphone 4s\n",
      "Name: text, dtype: object\n",
      "217326\n",
      "26558\n",
      "[[  0   0   0 ...,   7   8 332]\n",
      " [  0   0   0 ...,   0   0 246]\n",
      " [  0   0   0 ...,   9   9   9]\n",
      " ..., \n",
      " [  0   0   0 ...,   0 261  32]\n",
      " [  0   0   0 ...,  19 161 752]\n",
      " [  0   0   0 ...,  87  37 732]]\n"
     ]
    }
   ],
   "source": [
    "data = data[data.sentiment != \"Neutral\"]\n",
    "print(data['text'][0:5])\n",
    "data['text'] = data['text'].apply(lambda x: str(x).lower())\n",
    "print(\"------------------\")\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "print(data['text'][0:5])\n",
    "\n",
    "# replace all special chars with null\n",
    "\n",
    "print(data[ data['sentiment'] == 'pos'].size)\n",
    "print(data[ data['sentiment'] == 'neg'].size)\n",
    "\n",
    "i = 0\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(nb_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9753421e-1303-77d5-b17f-5f25fa08c452",
    "_uuid": "569f53e051f61f889b7195ff5461dd55089561b2"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "1ba3cf60-a83c-9c21-05e0-b14303027e93",
    "_uuid": "4b33ba1fd4f466bfed06c36092c4abca57b20a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 30, 128)       256000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 196)           254800      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2)             394         lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1], dropout=0.2))\n",
    "model.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15f4ee61-47e4-88c4-4b81-98a85237333f",
    "_uuid": "f599c78ae25b364b0cda9176d17986265bbe6592"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b35748b8-2353-3db2-e571-5fd22bb93eb0",
    "_uuid": "4d5cd7dce06666e8ef4f7158f08c2261741f07b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ..., \n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "(81701, 30) (81701, 2)\n",
      "(40241, 30) (40241, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values # one hot\n",
    "print(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2a775979-a930-e627-2963-18557d7bf6e6",
    "_uuid": "e1826df655ce57c35f277d41f983bb5240a803ed"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "d5e499ac-2eba-6ff7-8d9a-ff65eb04099b",
    "_uuid": "12c0197191c3a01386c6b1a5832e495ac108c67d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "471s - loss: 0.1895 - acc: 0.9370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f746a21a7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, nb_epoch = 1, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4ebd7bc1-53c0-0e31-a0b0-b6d0a3017434",
    "_uuid": "cef3a71832d51c5429f27acc8f08dd6b59483239"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "a970f412-722f-6d6d-72c8-325d0901ccef",
    "_uuid": "8ce1e8596f9ab612a81778b501fd7956e88b38ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.12\n",
      "acc: 0.96\n"
     ]
    }
   ],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]c\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "018ebf39-9414-27d0-232c-a34de051feaf",
    "_uuid": "b6fb480ec7f1344c38a7a40b63811d4b48e5f06c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1add73e9-c6fb-7e4c-8715-ea92f519d2a6",
    "_uuid": "f523bf5b3e732e5bd18a676932fa628396820a06"
   },
   "outputs": [],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "24c64f46-edd1-8d0b-7c7c-ef50fd26b2fd",
    "_uuid": "b8f1f15ca79f0ade0bc584cc2178b6002f24b100",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
